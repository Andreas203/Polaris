%
% BABA
symbol = 'BABA';
data = num2cell(readmatrix('stocks/BABA.csv').');
data = [data{:}];
numTimeStepsTrain = floor(0.999999999999*numel(data));
dataTrain = data(1:numTimeStepsTrain+1);
dataTest = data(numTimeStepsTrain+1:end);
mu = mean(dataTrain);
sig = std(dataTrain);
mu = mean(dataTrain);
sig = std(dataTrain);
dataTrainStandardized = (dataTrain - mu) / sig;
XTrain = dataTrainStandardized(1:end-1);
YTrain = dataTrainStandardized(2:end);
numFeatures = 1;
numResponses = 1;
numHiddenUnits = 200;
layers = [ ...
    sequenceInputLayer(numFeatures)
    lstmLayer(numHiddenUnits)
    fullyConnectedLayer(numResponses)
    regressionLayer];
options = trainingOptions('adam', ...
    'MaxEpochs',250, ...
    'GradientThreshold',1, ...
    'InitialLearnRate',0.005, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropPeriod',125, ...
    'LearnRateDropFactor',0.2, ...
    'Verbose',0, ...
    'Plots','training-progress');
net = trainNetwork(XTrain,YTrain,layers,options);
dataTestStandardized = (dataTest - mu) / sig;
XTest = dataTestStandardized(1:end-1);
net = predictAndUpdateState(net,XTrain);
[net,YPred] = predictAndUpdateState(net,YTrain(end));
numTimeStepsTest = numel(XTest);
for i = 2:numTimeStepsTest+7
    [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
end
YPred = sig*YPred + mu;
sprintf('%s: %f', symbol, YPred(7));

disp(YPred(7));
lastval = YPred(7);

for i = 1:YPred
    
end
S = jsonencode(YPred);
T = jsonencode(data);

conn = database('polarisanalytics','wvybtafwuesjox','4281f10d82eafab7f60f193fddb9b970c476af56b7b5c964f9faf952aeef0eb3');

query = compose("UPDATE companies SET change = %f WHERE companysymbol =  '%s'",YPred(7), symbol);
execute(conn, query);

query = compose("UPDATE companies SET pred = '%s' WHERE companysymbol =  '%s'",S, symbol);
execute(conn, query);

query = compose("UPDATE companies SET past = '%s' WHERE companysymbol =  '%s'",T, symbol);
execute(conn, query);

close(conn);

% %
% %
% %
% % GOOGL
% symbol = 'GOOGL';
% data = num2cell(readmatrix('stocks/GOOGL.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % AMZN
% symbol = 'AMZN';
% data = num2cell(readmatrix('stocks/AMZN.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% 
% %
% %
% %
% % AAPL
% symbol = 'AAPL'
% data = num2cell(readmatrix('stocks/AAPL.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % BIDU
% symbol = 'BIDU';
% data = num2cell(readmatrix('stocks/BIDU.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % CSCO
% symbol = 'CSCO';
% data = num2cell(readmatrix('stocks/CSCO.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % FB
% symbol = 'FB';
% data = num2cell(readmatrix('stocks/FB.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % IBM
% symbol = 'IBM';
% data = num2cell(readmatrix('stocks/IBM.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % INTC
% symbol = 'INTC';
% data = num2cell(readmatrix('stocks/INTC.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % MSFT
% symbol = 'MSFT';
% data = num2cell(readmatrix('stocks/MSFT.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % NFLX
% symbol = 'NFLX';
% data = num2cell(readmatrix('stocks/NFLX.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % ORCL
% symbol = 'ORCL';
% data = num2cell(readmatrix('stocks/ORCL.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % PYPL
% symbol = 'PYPL';
% data = num2cell(readmatrix('stocks/PYPL.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % CRM
% symbol = 'CRM';
% data = num2cell(readmatrix('stocks/CRM.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % SSNLF
% symbol = 'SSNLF';
% data = num2cell(readmatrix('stocks/SSNLF.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % SAP
% symbol = 'SAP';
% data = num2cell(readmatrix('stocks/SAP.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % SFTBY
% symbol = 'SFTBY';
% data = num2cell(readmatrix('stocks/SFTBY.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % TCEHY
% symbol = 'TCEHY'
% data = num2cell(readmatrix('stocks/TCEHY.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % TSLA
% symbol = 'TSLA';
% data = num2cell(readmatrix('stocks/TSLA.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% %
% % TWTR
% symbol = 'TWTR';
% data = num2cell(readmatrix('stocks/TWTR.csv').');
% data = [data{:}];
% numTimeStepsTrain = floor(0.999999999999*numel(data));
% dataTrain = data(1:numTimeStepsTrain+1);
% dataTest = data(numTimeStepsTrain+1:end);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% mu = mean(dataTrain);
% sig = std(dataTrain);
% dataTrainStandardized = (dataTrain - mu) / sig;
% XTrain = dataTrainStandardized(1:end-1);
% YTrain = dataTrainStandardized(2:end);
% numFeatures = 1;
% numResponses = 1;
% numHiddenUnits = 200;
% layers = [ ...
%     sequenceInputLayer(numFeatures)
%     lstmLayer(numHiddenUnits)
%     fullyConnectedLayer(numResponses)
%     regressionLayer];
% options = trainingOptions('adam', ...
%     'MaxEpochs',250, ...
%     'GradientThreshold',1, ...
%     'InitialLearnRate',0.005, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',125, ...
%     'LearnRateDropFactor',0.2, ...
%     'Verbose',0, ...
%     'Plots','training-progress');
% net = trainNetwork(XTrain,YTrain,layers,options);
% dataTestStandardized = (dataTest - mu) / sig;
% XTest = dataTestStandardized(1:end-1);
% net = predictAndUpdateState(net,XTrain);
% [net,YPred] = predictAndUpdateState(net,YTrain(end));
% numTimeStepsTest = numel(XTest);
% for i = 2:numTimeStepsTest+7
%     [net,YPred(:,i)] = predictAndUpdateState(net,YPred(:,i-1),'ExecutionEnvironment','gpu');
% end
% YPred = sig*YPred + mu;
% sprintf('%s: %f', symbol, YPred(7))
% %
% %
% 
% 
% 
% 
